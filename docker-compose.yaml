version: '3'

services:
  kafka:
    image: 'bitnami/kafka:latest'
    container_name: kafka_broker
    ports:
      - '9094:9094'
    environment:
      # KRaft settings 
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=controller,broker 
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@kafka:9093 
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER 
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT 
      # For safety reasons, do not use this flag in a production environment.
      - ALLOW_PLAINTEXT_LISTENER=yes  # the listener will be without authentication and non-encrypted
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,EXTERNAL://127.0.0.1:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT

    volumes:
      - /kafka/data:/bitnami/kafka

  rabbitmq:
    build:
      context: ./rabbitmq
    container_name: rabbitmq_broker
    ports:
        - 5672:5672
        - 15672:15672
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
  
  # TODO: disabled until the new consumer be available
  # spark:
  #   container_name: spark_master
  #   image: docker.io/bitnami/spark:3.4
  #   environment:
  #     - SPARK_MODE=master
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #     - SPARK_USER=spark
  #   ports:
  #     - '8080:8080'

  # spark-worker:
  #   container_name: spark_worker
  #   image: docker.io/bitnami/spark:3.4
  #   environment:
  #     - SPARK_MODE=worker
  #     - SPARK_MASTER_URL=spark://spark:7077
  #     - SPARK_WORKER_MEMORY=1G
  #     - SPARK_WORKER_CORES=1
  #     - SPARK_RPC_AUTHENTICATION_ENABLED=no
  #     - SPARK_RPC_ENCRYPTION_ENABLED=no
  #     - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
  #     - SPARK_SSL_ENABLED=no
  #     - SPARK_USER=spark

volumes:
  rabbitmq_data:
    driver: local